{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c9567f-d149-4027-960c-509ab962f034"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fe48ef1-ad8c-4865-939d-737949d5403f"
      },
      "source": [
        "# **Lab: Building Advanced Transformers**\n",
        "\n",
        "**Estimated time needed: 30 minutes**\n",
        "\n",
        "In this lab, you will implement and experiment with advanced Transformer models using Keras.\n",
        "\n",
        "**Learning objectives:**\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "- Understand the core components of a Transformer architecture.\n",
        "- Implement a multi-head self-attention mechanism from scratch.\n",
        "- Train and evaluate a Transformer for time series prediction.\n",
        "- Handle preprocessing and scaling for time series data effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9085021a-0940-4cce-b377-55c6ed324689"
      },
      "source": [
        "## What is a Transformer?\n",
        "\n",
        "The Transformer architecture was introduced in the paper _\"Attention Is All You Need\"_. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
        "\n",
        "### Key Components:\n",
        "\n",
        "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
        "- **Positional Encoding:** Injects information about the position of input tokens.\n",
        "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
        "- **Feedforward Layers:** Process the attended information.\n",
        "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
        "\n",
        "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
        "\n",
        "**Next:** You will implement parts of this architecture step-by-step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc0932f5-ca9b-4c8e-8071-fb7602700393"
      },
      "source": [
        "## Step-by-Step Instructions:\n",
        "\n",
        "### Step 1: Import necessary libraries\n",
        "\n",
        "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57093c77-cb7a-49b3-b5b4-0bd3fe7d0dac"
      },
      "outputs": [],
      "source": [
        "%pip install tensorflow pyarrow\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install matplotlib\n",
        "%pip install requests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f1250cc-a6d2-442b-8c5f-87f880c41425"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5555bbf4-0d2b-494c-876d-163f73adfe38"
      },
      "source": [
        "#### Setup the Environment to generate synthetic stock price data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad25744-9da7-407e-aafb-7727191155c5",
        "outputId": "63679289-6a47-42c4-98ad-0ce80bf2601d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthetic stock_prices.csv created and loaded.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a synthetic stock price dataset\n",
        "np.random.seed(42)\n",
        "data_length = 2000  # Adjust data length as needed\n",
        "trend = np.linspace(100, 200, data_length)\n",
        "noise = np.random.normal(0, 2, data_length)\n",
        "synthetic_data = trend + noise\n",
        "\n",
        "# Create a DataFrame and save as 'stock_prices.csv'\n",
        "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
        "data.to_csv('stock_prices.csv', index=False)\n",
        "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5437c3-535c-4fc9-897d-f90b931a0253",
        "outputId": "27a49e16-49ec-4c5b-a1a8-36045958e2e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (1899, 100, 1)\n",
            "Shape of Y: (1899,)\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stock_prices.csv')\n",
        "data = data[['Close']].values\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for training\n",
        "def create_dataset(data, time_step=1):\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(data)-time_step-1):\n",
        "        a = data[i:(i+time_step), 0]\n",
        "        X.append(a)\n",
        "        Y.append(data[i + time_step, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "time_step = 100\n",
        "X, Y = create_dataset(data, time_step)\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of Y:\", Y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e4b5d6f-1d42-4ab5-b26a-99202a05ed2e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "`tensorflow` is the main library for machine learning in Python.\n",
        "\n",
        "`stock_prices.csv` is the data set that is loaded.\n",
        "\n",
        "`MinMaxScaler` method is used to normalize the data.\n",
        "\n",
        "`create_dataset`method is used to prepare the data for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d9cc83-c862-468a-9095-33d79366b3e6"
      },
      "source": [
        "### Step 2: Implement Multi-Head Self-Attention\n",
        "\n",
        "Define the Multi-Head Self-Attention mechanism.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a5493e3-c54b-4c7b-b91f-e860cde8076f"
      },
      "outputs": [],
      "source": [
        "# Define a custom layer for Multi-Head Self-Attention mechanism\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        # Initialize the layer with embedding dimension and number of attention heads\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim  # Total embedding dimension\n",
        "        self.num_heads = num_heads  # Number of attention heads\n",
        "        self.projection_dim = embed_dim // num_heads  # Dimension of each attention head\n",
        "        # Dense layers for transforming input into query, key and value\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim) \n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        # Dense layer to combine outputs of attention heads\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "    def attention(self, query, key, value):\n",
        "        # Compute attention scores between query and key\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        # Get dimension of key for scaling\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        # Scale dot product to prevent exploding gradients\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        # Apply softmax to get attention weights\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        # Compute weighted sum of values\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Reshape input to separate heads\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        # Transpose to get shape [batch_size, num_heads, seq_length, projection_dim]\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Get batch size from input shape\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        # Create query, key and value projections\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        # Split projections into multiple heads\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        # Compute scaled dot-product attention\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        # Reshape attention output to original dimensions\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        # Combine heads using dense layer\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30cc2f47-4ce0-474e-93b6-7a472cbda8eb"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously.\n",
        "\n",
        "- The attention parameter computes the attention scores and weighted sum of the values.\n",
        "\n",
        "- The split_heads parameter splits the input into multiple heads for parallel attention computation.\n",
        "\n",
        "- The call method applies the self-attention mechanism and combines the heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310949fe-6515-463f-b269-4e0e8d5f7298"
      },
      "source": [
        "### Step 3: Implement Transformer block\n",
        "\n",
        "Define the Transformer block.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48bd3693-2152-4a24-bced-b5fcc2b93ebb"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(Layer):\n",
        "    # Initialize the Transformer block with embedding dimension, number of heads, feedforward dimension and dropout rate\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # Create multi-head self-attention layer\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        \n",
        "        # Create feedforward network with two dense layers\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),  # First dense layer with ReLU activation\n",
        "            Dense(embed_dim),                  # Second dense layer projecting back to embed_dim\n",
        "        ])\n",
        "\n",
        "        # Create layer normalization layers\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)  # For attention output\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)  # For feedforward output\n",
        "        \n",
        "        # Create dropout layers for regularization\n",
        "        self.dropout1 = Dropout(rate)  # Dropout after attention\n",
        "        self.dropout2 = Dropout(rate)  # Dropout after feedforward\n",
        "\n",
        "    # Forward pass of the transformer block\n",
        "    def call(self, inputs, training):\n",
        "        # Apply self-attention mechanism\n",
        "        attn_output = self.att(inputs)\n",
        "        \n",
        "        # Apply dropout to attention output during training\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        \n",
        "        # Add residual connection and normalize\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        \n",
        "        # Pass through feedforward network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        \n",
        "        # Apply dropout to feedforward output during training\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        \n",
        "        # Add second residual connection and normalize\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "009b3148-bfac-4d31-83cb-150f3bdc0eee"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.\n",
        "\n",
        "- Dropout is used to prevent overfitting.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "268a11b0-cbc9-46ce-bec2-f6b753869d26"
      },
      "source": [
        "### Step 4: Implement Encoder Layer\n",
        "\n",
        "Define the Encoder layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c8fee5e-d3a2-42d8-9ebc-c32501d506aa"
      },
      "outputs": [],
      "source": [
        "# Define a custom layer for the Encoder part of the Transformer\n",
        "class EncoderLayer(Layer):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        # Initialize the encoder layer with embedding dimension, number of heads, feedforward dimension and dropout rate\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        # Create multi-head self-attention layer\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        # Create feedforward network with two dense layers\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),  # First dense layer with ReLU activation\n",
        "            Dense(embed_dim),                  # Second dense layer projecting back to embed_dim\n",
        "        ])\n",
        "\n",
        "        # Create layer normalization layers\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)  # For attention output\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)  # For feedforward output\n",
        "        \n",
        "        # Create dropout layers for regularization\n",
        "        self.dropout1 = Dropout(rate)  # Dropout after attention\n",
        "        self.dropout2 = Dropout(rate)  # Dropout after feedforward\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        # Apply self-attention mechanism to the inputs\n",
        "        attn_output = self.att(inputs)\n",
        "        # Apply dropout to attention output during training\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # Add residual connection and normalize\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        # Pass through feedforward network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        # Apply dropout to feedforward output during training\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # Add second residual connection and normalize\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77515712-2fdb-4145-bf20-40370d382697"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture.\n",
        "\n",
        "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network.\n",
        "\n",
        "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer.\n",
        "\n",
        "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53aa4eb1-ed2d-4e5f-a6c3-3cb3fbf97c3a"
      },
      "source": [
        "### Step 5: Implement Transformer encoder\n",
        "\n",
        "Define the Transformer Encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645323a2-b3e6-4d5c-855f-bd26e8725d60",
        "outputId": "1d0e3841-2f89-4a92-988e-ff78b18ceb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 100, 128)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout\n",
        "\n",
        "# Define MultiHeadSelfAttention layer that inherits from the base Layer class\n",
        "class MultiHeadSelfAttention(Layer):\n",
        "    # Initialize the layer with embedding dimension and number of attention heads\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        # Set embedding dimension\n",
        "        self.embed_dim = embed_dim\n",
        "        # Set number of attention heads\n",
        "        self.num_heads = num_heads\n",
        "        # Calculate projection dimension for each head\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        # Create dense layers for query, key and value transformations\n",
        "        self.query_dense = Dense(embed_dim)\n",
        "        self.key_dense = Dense(embed_dim)\n",
        "        self.value_dense = Dense(embed_dim)\n",
        "        # Create dense layer to combine attention heads\n",
        "        self.combine_heads = Dense(embed_dim)\n",
        "\n",
        "    # Compute attention scores and weighted sum\n",
        "    def attention(self, query, key, value):\n",
        "        # Compute dot product between query and key\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        # Get dimension of key for scaling\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        # Scale dot product to prevent gradient explosion\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        # Apply softmax to get attention weights\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        # Compute weighted sum of values\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "\n",
        "    # Split the input tensor into multiple heads\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Reshape input to separate attention heads\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        # Transpose dimensions to get correct shape\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # Forward pass of the attention layer\n",
        "    def call(self, inputs):\n",
        "        # Get batch size from input shape\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        # Create query, key and value projections\n",
        "        query = self.query_dense(inputs)\n",
        "        key = self.key_dense(inputs)\n",
        "        value = self.value_dense(inputs)\n",
        "        # Split projections into multiple heads\n",
        "        query = self.split_heads(query, batch_size)\n",
        "        key = self.split_heads(key, batch_size)\n",
        "        value = self.split_heads(value, batch_size)\n",
        "        # Apply attention mechanism\n",
        "        attention, _ = self.attention(query, key, value)\n",
        "        # Reshape attention output\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
        "        # Combine heads\n",
        "        output = self.combine_heads(concat_attention)\n",
        "        return output\n",
        "\n",
        "# Define TransformerBlock layer that combines attention and feedforward network\n",
        "class TransformerBlock(Layer):\n",
        "    # Initialize the transformer block\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # Create multi-head self-attention layer\n",
        "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        # Create feedforward network\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(ff_dim, activation=\"relu\"),\n",
        "            Dense(embed_dim),\n",
        "        ])\n",
        "        # Create layer normalization and dropout layers\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    # Forward pass of the transformer block\n",
        "    def call(self, inputs, training):\n",
        "        # Apply attention mechanism\n",
        "        attn_output = self.att(inputs)\n",
        "        # Apply dropout to attention output\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # Add residual connection and normalize\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        # Pass through feedforward network\n",
        "        ffn_output = self.ffn(out1)\n",
        "        # Apply dropout to feedforward output\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # Add residual connection and normalize\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Define TransformerEncoder that stacks multiple transformer blocks\n",
        "class TransformerEncoder(Layer):\n",
        "    # Initialize the encoder with specified number of layers and dimensions\n",
        "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        # Set number of layers and embedding dimension\n",
        "        self.num_layers = num_layers\n",
        "        self.embed_dim = embed_dim\n",
        "        # Create list of transformer blocks\n",
        "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)]\n",
        "        # Create dropout layer\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    # Forward pass through all transformer blocks\n",
        "    def call(self, inputs, training=False):\n",
        "        # Pass input through each transformer block sequentially\n",
        "        x = inputs\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training=training)\n",
        "        return x\n",
        "\n",
        "# Example usage\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "inputs = tf.random.uniform((1, 100, embed_dim))\n",
        "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training'\n",
        "print(outputs.shape)  # Should print (1, 100, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b5887f5-beb2-4896-ac61-5aa3b1a8b43f"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a56ba42-9248-4dd6-8cd0-5182562a6ab5"
      },
      "source": [
        "### Step 6: Build and Compile the Transformer model\n",
        "\n",
        "Integrate the Transformer Encoder into a complete model for sequential data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "bcbf4111-b2e8-4b0c-b625-20095535d9f9",
        "outputId": "9d69c07d-fad4-4c1f-92c2-25f634e713f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define the necessary parameters\n",
        "\n",
        "embed_dim = 128\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_layers = 4\n",
        "\n",
        "# Define the Transformer Encoder\n",
        "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim)\n",
        "\n",
        "# Build the model\n",
        "input_shape = (X.shape[1], X.shape[2])\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Project the inputs to the embed_dim\n",
        "x = tf.keras.layers.Dense(embed_dim)(inputs)\n",
        "encoder_outputs = transformer_encoder(x)\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "outputs = tf.keras.layers.Dense(1)(flatten)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "866c5677-9d64-4761-87c3-0428ddbd7d8e"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.\n",
        "\n",
        "- The model is then compiled with the Adam optimizer and mean squared error loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e650c957-3d8d-4a63-839f-2f1121c439a6"
      },
      "source": [
        "### Step 7: Train the Transformer model\n",
        "\n",
        "Train the model on the prepared dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b88ba571-72b8-4744-bdf5-c540e0d88124",
        "outputId": "64b41793-83a0-4955-f4fd-895bbaa8b80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 162ms/step - loss: 16.4223\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.2313\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1937\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1565\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2172\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1349\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1311\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1431\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1718\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1079\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1288\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1060\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1401\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0866\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0708\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0852\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0646\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0531\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0822\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0446\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f5671114890>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57e8051c-8d75-44cb-ae77-ce8e6a1ea8bc"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8eff4c1-817e-4c0e-bc4d-6a8225e1ac63"
      },
      "source": [
        "### Step 8: Evaluate and Make Predictions\n",
        "\n",
        "Evaluate the model's performance and make predictions on the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "8a2c475e-7eca-43c5-8f9f-5c251fad62ec",
        "outputId": "c31bb0cb-3d03-408b-8da4-09a844b1e4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make predictions\n",
        "predictions = model.predict(X)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "\n",
        "# Prepare true values for comparison\n",
        "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
        "\n",
        "# Plot the predictions vs true values\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(true_values, label='True Data')\n",
        "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend()\n",
        "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54508aee-14a9-4415-900d-d60a0ab6a123"
      },
      "source": [
        "In the above code:\n",
        "\n",
        "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler.\n",
        "\n",
        "- The true data and predictions are plotted to visualize the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d67c9e0-704c-4885-96a1-2f0583b656bc"
      },
      "source": [
        "## Practice Exercises:\n",
        "\n",
        "### Exercise 1: Add dropout to the Transformer model\n",
        "\n",
        "**Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "- Add a dropout layer after the Flatten layer in the model.\n",
        "\n",
        "- Set the dropout rate to 0.5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7afb541b-ff6f-4d84-969e-acc846ddf708",
        "outputId": "85c5eb62-157e-4fac-aa1c-f1237520d8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 220ms/step - loss: 6.2090\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.4183\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.7889\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.3822\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1815\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0867\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0468\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0346\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0314\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0292\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0200\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0207\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0183\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0154\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0143\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0134\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0126\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0105\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0101\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0108\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.9348e-04\n",
            "Test loss: 0.0008436692878603935\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss: {loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca356342-d1da-4811-adc8-520b2cbf9de1"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "\n",
        "\n",
        "# Add a dropout layer after the Flatten layer\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(encoder_outputs)\n",
        "\n",
        "dropout = Dropout(0.5)(flatten)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(1)(dropout)\n",
        "\n",
        "\n",
        "\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "loss = model.evaluate(X, Y)\n",
        "\n",
        "print(f'Test loss: {loss}')\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72dc58a7-057f-4582-b0a2-38ecae4fc6d7"
      },
      "source": [
        "### Exercise 2: Experiment with different batch sizes\n",
        "\n",
        "**Objective: Observe the impact of different batch sizes on model performance.**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "- Train the model with a batch size of 16.\n",
        "\n",
        "- Train the model with a batch size of 64.\n",
        "\n",
        "- Compare the training time and performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e9d62a0-821f-4050-a59a-e10c6155e799",
        "outputId": "fa988455-c618-46a2-c19f-fe59f8b70136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0180\n",
            "Epoch 2/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0232\n",
            "Epoch 3/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0454\n",
            "Epoch 4/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0245\n",
            "Epoch 5/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0215\n",
            "Epoch 6/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0301\n",
            "Epoch 7/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0231\n",
            "Epoch 8/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0247\n",
            "Epoch 9/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 10/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0207\n",
            "Epoch 11/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0284\n",
            "Epoch 12/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 13/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0154\n",
            "Epoch 14/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0218\n",
            "Epoch 15/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0134\n",
            "Epoch 16/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0278\n",
            "Epoch 17/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0138\n",
            "Epoch 18/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0145\n",
            "Epoch 19/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0249\n",
            "Epoch 20/20\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0111\n",
            "Test loss with batch size 16: 0.007741543464362621\n",
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 395ms/step - loss: 0.0092\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - loss: 0.0048\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0036\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0033\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0030\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0030\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0033\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0030\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0040\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0030\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0031\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0034\n",
            "Epoch 13/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0026\n",
            "Epoch 14/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0035\n",
            "Epoch 15/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0033\n",
            "Epoch 16/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0030\n",
            "Epoch 17/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0027\n",
            "Epoch 18/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0031\n",
            "Epoch 19/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0031\n",
            "Epoch 20/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0028\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3145e-04\n",
            "Test loss with batch size 64: 0.0005152664380148053\n"
          ]
        }
      ],
      "source": [
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2b52fb1-841e-4354-b73c-f5bd9bc8c4da"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Train the model with batch size 16\n",
        "model.fit(X, Y, epochs=20, batch_size=16)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 16: {loss}')\n",
        "\n",
        "# Train the model with batch size 64\n",
        "model.fit(X, Y, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with batch size 64: {loss}')\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c6ca2ca-fa3b-419f-b968-db4fc397c162"
      },
      "source": [
        "### Exercise 3: Use a different activation function\n",
        "\n",
        "**Objective: Understand how different activation functions impact the model performance.**\n",
        "\n",
        "Instructions:\n",
        "\n",
        "- Change the activation function of the Dense layer to `tanh`.\n",
        "\n",
        "- Train and evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2fc2f6b-ff5d-45cf-9913-5eed4cd18d82",
        "outputId": "e6bb664d-6579-4a45-ef91-12fd5ae445ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 161ms/step - loss: 0.2191\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0287\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0147\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0063\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0078\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0044\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0029\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0037\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0030\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0046\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0035\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0025\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0029\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0040\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0028\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0026\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0032\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 6.9065e-04\n",
            "Test loss with tanh activation: 0.0009209996205754578\n"
          ]
        }
      ],
      "source": [
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a87742a7-6c71-4d70-9c03-b0b81a869fff"
      },
      "source": [
        "<details><summary>Click here to view the solution.</summary>\n",
        "\n",
        "```\n",
        "# Change the activation function of the Dense layer to tanh\n",
        "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, Y, epochs=20, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X, Y)\n",
        "print(f'Test loss with tanh activation: {loss}')\n",
        "\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d517b5e4-01f0-466d-88aa-80708f52264f"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edafaf7b-0e83-4d03-910b-587b5d5578c8"
      },
      "source": [
        "Copyright © IBM Corporation. All rights reserved.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
